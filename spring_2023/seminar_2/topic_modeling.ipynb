{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "615a4130",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ae7b50",
   "metadata": {},
   "source": [
    "## Reading\n",
    "* [Topic Coherence](https://svn.aksw.org/papers/2015/WSDM_Topic_Evaluation/public.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f830c2",
   "metadata": {},
   "source": [
    "## 1 Problem statement\n",
    "Topic modeling is equivalent to soft clustering:   \n",
    "Given document ${d_j}$, assign each document a vector of probabilities for  each cluster $v_j = [p(c_0), ... , p(c_K)]$,   \n",
    "$\\sum_k p(c_k) = 1$\n",
    "\n",
    "Usually,  \n",
    "* number of clusters K is fixed and is a subject for cross-validation.\n",
    "* document is described by term-document matrix (bag of words model)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fb95f4",
   "metadata": {},
   "source": [
    "## 2 Latent Semantic Analysis\n",
    "\n",
    "LSA = term-document matrix + Truncated SVD\n",
    "\n",
    "<img src=images/lsa.png style=\"height:200px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf392d53",
   "metadata": {},
   "source": [
    "## 3 PLSA\n",
    "\n",
    "<img src=images/plsa.png height=400/>\n",
    "\n",
    "Let  \n",
    "$w$ - set of words  \n",
    "$d$ - set of documents  \n",
    "$t$ - implicit topics  \n",
    "\n",
    "Joint probability of term and document assuming $p(w|t,d) = p(w | t)$\n",
    "$$p(w,d) = \\sum_t p(t) p(w|t) p(d|t) = \\sum_t p(d) p(w|t) p(t|d) = \\sum_t p(w) p(t|w) p(d|t) $$\n",
    "\n",
    "Likelihood\n",
    "\n",
    "$$ \\ln \\prod_{d,w}p(w,d)^{n_{dw}} = \\sum_{w \\in d, d \\in D} n_{wd} \\ln p(w|d) + \\sum_{d \\in D} \\ln p(d) $$\n",
    "\n",
    "$$ \\sum_{w \\in d, d \\in D} n_{wd} \\ln p(w|d) = \\sum_{w \\in d, d \\in D} n_{wd} \\ln \\sum_{t \\in T} p(w|t) p(t|d) = \n",
    "\\sum_{w \\in d, d \\in D} n_{wd} \\ln \\sum_{t \\in T} \\phi_{wt} \\theta_{td} $$\n",
    "\n",
    "\n",
    "$\\sum_w \\phi_{wt} = 1$, $\\phi_{wt} > 0$  \n",
    "$\\sum_t \\theta_{td} = 1$m, \n",
    "\n",
    "$p(d) = \\frac {n_d} {\\sum_d {n_d}}$ prior distribution over documents, n_d document length  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114c05bd",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "E-step\n",
    "\n",
    "$$p(t|d,w) = \\frac {p(w,t|d)} {p(w|d)} = \\frac {p(w|t)p(t|d)} {p(w|d)} = \\frac {\\phi_{wt} \\theta_{td}} {\\sum_{s \\in T} \\phi_{ws} \\theta_{sd} }$$\n",
    "\n",
    "$$ n_{dwt} = n_{dw}p(t |d,w) = n_{dw} \\frac {\\phi_{wt} \\theta_{td}} {\\sum_{s \\in T} \\phi_{ws} \\theta_{sd} } $$\n",
    "\n",
    "M-step\n",
    "\n",
    "$$ \\phi_{wt} = \\frac {n_{dwt}} {n_t}$$\n",
    "$$ \\theta_{td} = \\frac {n_{dt}} {n_d}$$\n",
    "\n",
    "$ n_{dt} = \\sum_{w} n_{dwt}$  \n",
    "$ n_{wt} = \\sum_{d} n_{dwt}$  \n",
    "$ n_{t} = \\sum_{w} n_{wt}$  \n",
    "$ n_{d} = \\sum_{t} n_{dt}$  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278d8d3a",
   "metadata": {},
   "source": [
    "### Properties\n",
    "\n",
    "* $\\Phi$, $\\Theta$ - are unstable\n",
    "* easily overfits\n",
    "* do not scale well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b589f397",
   "metadata": {},
   "source": [
    "## 4 Latent Dirichlet Allocation\n",
    "\n",
    "We demand, that $p(w|t)$, $p(t|d)$ have Dirichlet distribution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca55bfa",
   "metadata": {},
   "source": [
    "**simplex** is a set of points $\\{z |  \\sum_{i=1}^k z_i = 1  \\wedge z_i \\geq0 \\}$\n",
    "\n",
    "\n",
    "<img src=images/dir.jpeg style='height:200px'/>\n",
    "\n",
    "\n",
    "**Dirichlet distribution** on simplex\n",
    "\n",
    "$$Dir(z | \\alpha) = \\frac {\\Gamma(\\alpha_0)}{\\prod_i \\Gamma(\\alpha_i)} \\prod_{i=1}^k z_i^{\\alpha_i-1}$$\n",
    ", where  \n",
    "$\\alpha_i > 0$  \n",
    "$\\alpha_0 = \\sum_i \\alpha_i$\n",
    "\n",
    "\n",
    "<img src=images/lda.png style='height:200px'/>\n",
    "\n",
    "where   \n",
    "$$\\theta_d \\sim Dir(\\theta, \\alpha) = \\frac {\\Gamma(\\alpha_0)}{\\prod_t \\Gamma(\\alpha_t)}  \\prod_t \\theta_{td}^{\\alpha_t-1}$$\n",
    "\n",
    "$$\\phi_t \\sim Dir(\\theta, \\beta) = \\frac {\\Gamma(\\beta_0)}{\\prod_w \\Gamma(\\beta_w)}  \\prod_w \\phi_{wt}^{\\beta_w-1}$$\n",
    "\n",
    "\n",
    "Likelihood\n",
    "\n",
    "$$L = \\ln \\prod_{i} p(d_i, w_i | \\Theta, \\Phi) p(\\Theta | \\alpha) p(\\Phi | \\beta)$$\n",
    "$$L = \\ln \\prod_{dw} p(d, w | \\Theta, \\Phi)^{n_{dw}} \\prod_d p(\\theta_d | \\alpha) \\prod_t p(\\phi_t | \\beta) $$\n",
    "$$L = \\sum_{w \\in d, d \\in D} n_{wd} \\ln \\sum_{t \\in T} \\phi_{wt} \\theta_{td} + \\sum_{dt} \\ln \\theta_{td}^{\\alpha_t-1} + \\sum_{tw} \\phi_{wt}^{\\beta_w - 1} $$\n",
    "$$L = \\sum_{w \\in d, d \\in D} n_{wd} \\ln \\sum_{t \\in T} \\phi_{wt} \\theta_{td} + \\sum_{dt} (\\alpha_t-1)\\ln \\theta_{td} + \\sum_{tw} (\\beta_w - 1) \\phi_{wt} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9e72ea",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "E-step\n",
    "\n",
    "$$p(t|dw) = {norm}_{t}(\\phi_{wt}\\theta_{td}) $$\n",
    "\n",
    "M-step\n",
    "\n",
    "$$ \\phi_{wt} = {norm}_w (n_{wt} + \\beta_w - 1) $$\n",
    "$$ \\theta_{td} = {norm}_w (n_{td} + \\alpha_t - 1) $$\n",
    "\n",
    "$n_{wt} = \\sum_d n_{dw} p(t|dw)$  \n",
    "$n_{wt} = \\sum_w n_{dw} p(t|dw)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3e6229",
   "metadata": {},
   "source": [
    "### Generation from LDA model\n",
    "\n",
    "* sample $\\theta_d$ and $\\phi_t$\n",
    "* for each term position $i$ in document $d$\n",
    "* sample $t_i \\sim p(t|d)$\n",
    "* sample $w_i \\sim p(w|t_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3aa896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84e905e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded96509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5933f159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ccdf14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e63bb17",
   "metadata": {},
   "source": [
    "## 5 Additive Regularized Topic Models\n",
    "\n",
    "$$L(\\Phi, \\Theta) + \\sum_{i=1}^r \\tau_i c$$\n",
    "\n",
    "$R_i$ - continously differentiable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43075593",
   "metadata": {},
   "source": [
    "Example for LDA\n",
    "\n",
    "$$ \\sum_d KL(\\alpha_t | \\theta_{td}) \\rightarrow min $$\n",
    "$$ \\sum_w KW(\\beta_w | \\phi_{wt}) \\rightarrow min $$\n",
    "\n",
    "$$ R(\\Phi, \\Theta) = \\beta_0 \\sum_t \\sum_w \\beta_w \\ln \\phi_{wt} + \\alpha_0 \\sum_d \\sum_t \\alpha_t \\ln \\theta_{td} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3466f0e",
   "metadata": {},
   "source": [
    "Example for sparse regularizer\n",
    "\n",
    "$$ R(\\Phi, \\Theta) = -\\beta_0 \\sum_t \\sum_w \\beta_w \\ln \\phi_{wt} - \\alpha_0 \\sum_d \\sum_t \\alpha_t \\ln \\theta_{td} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc5ab96",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "E-step\n",
    "\n",
    "$$p(t|dw) = {norm}_{t}(\\phi_{wt}\\theta_{td}) $$\n",
    "\n",
    "M-step\n",
    "\n",
    "$$ \\phi_{wt} = {norm}_w (n_{wt} + \\phi_{wt} \\frac {\\partial R} {\\partial \\phi_{wt}}) $$\n",
    "$$ \\theta_{td} = {norm}_w (n_{td} + \\theta_{td} \\frac {\\partial R} {\\partial \\theta_{td}}) $$\n",
    "\n",
    "$n_{wt} = \\sum_d n_{dw} p(t|dw)$  \n",
    "$n_{wt} = \\sum_w n_{dw} p(t|dw)$  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de20396",
   "metadata": {},
   "source": [
    "## 6 Evalutation\n",
    "\n",
    "### Likelihood\n",
    "\n",
    "$$ L(\\Phi, \\Theta) = \\sum_d \\sum_w n_{dw} \\ln p(w|d)  $$\n",
    "\n",
    "### Perplexity\n",
    "\n",
    "$$ PL(D) = \\exp(-\\frac 1 n \\sum_d \\sum_w n_{dw} \\ln p(w|d))  $$\n",
    "\n",
    "$ n = \\sum_d \\sum_w n_{dw}$\n",
    "\n",
    "\n",
    "### Topic Coherence\n",
    "\n",
    "Algorithm sketch:\n",
    "1. Each topic is described by top-n most probable words.\n",
    "1. Introduce similarity measure between words: e.g. based on co-occurance matrix or cosine distance between word embeedings\n",
    "1. Compute average of pairwise similarities of top-n words for each topic\n",
    "1. Average scores over topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c16b918",
   "metadata": {},
   "source": [
    "## 7 NN for Aspect Learning\n",
    "\n",
    "<img src=images/aspect.png style=\"height:300px\"/>\n",
    "\n",
    "where  \n",
    "sentence embedding \n",
    "$$z_s = \\sum_{i}^n \\alpha_i e_{w_i}$$\n",
    "\n",
    "attention weight\n",
    "$$a_i = softmax(d_i)$$  \n",
    "$$d_i = e_{w_i}^T M y_s$$\n",
    "\n",
    "sentence context\n",
    "$$y_s = \\frac 1 n \\sum_{i=1}^n e_{w_i}$$\n",
    "\n",
    "\n",
    "reconstructed sentence embedding\n",
    "$$p_t = softmax(W z_s + b)$$  \n",
    "$$r_s = T^T p_t$$   \n",
    "$T$ matrix of aspect embeddings  \n",
    "\n",
    "\n",
    "**Training objective**:\n",
    "$$ J = \\sum_{s \\in D} \\sum_{i=1}^n max(0, 1-r_s z_s + r_s n_i) + \\lambda ||T^T T - I ||  $$\n",
    "where   \n",
    "$m$ random sentences are sampled as negative examples  \n",
    "$n_i$ average of word embeddings in the i-th sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4282dde5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
