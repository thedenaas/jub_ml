{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd30fb48",
   "metadata": {},
   "source": [
    "# Assignment 1. Learning to Rank\n",
    "\n",
    "Download MQ2007 dataset from [here](https://1drv.ms/f/s!Aqi9ONgj3OqPaynoZZSZVfHPJd0).  \n",
    "For this assignment we will **use only Fold1**  \n",
    "\n",
    "Data split: train, validation and test datasets are given.  \n",
    "**You have to use hold-out validation to justify hyperparam selection.**  \n",
    "**In each task you need to surpass baseline.**\n",
    "\n",
    "Quality metric: NDCG@10\n",
    "\n",
    "Data description:  \n",
    "*relevance* - bigger the better  \n",
    "*qid* - query id  \n",
    "*docid* - document id  \n",
    "*features* - 46-dim human-engineered feature vector   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c5b1b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def preprocess(filename):\n",
    "    df = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            rec = {}\n",
    "            items = line.split()\n",
    "            rec['relevance'] = int(items[0])\n",
    "            rec['qid'] = int(items[1].split(':')[1])\n",
    "            rec['features'] = [float(items[i].split(':')[1]) for i in range(2,2+46)]\n",
    "            rec['docid'] = items[50]\n",
    "            df.append(rec)\n",
    "    df = pd.DataFrame(df)\n",
    "    return df\n",
    "    \n",
    "\n",
    "df_train = preprocess('MQ2007/Fold1/train.txt')\n",
    "df_valid = preprocess('MQ2007/Fold1/vali.txt')\n",
    "df_test = preprocess('MQ2007/Fold1/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "738a76fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relevance</th>\n",
       "      <th>qid</th>\n",
       "      <th>features</th>\n",
       "      <th>docid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>GX000-00-0000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.03131, 0.666667, 0.5, 0.166667, 0.033206, 0...</td>\n",
       "      <td>GX000-24-12369390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.078682, 0.166667, 0.5, 0.333333, 0.080022, ...</td>\n",
       "      <td>GX000-62-7863450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.019058, 1.0, 1.0, 0.5, 0.022591, 0.0, 0.0, ...</td>\n",
       "      <td>GX016-48-5543459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.039477, 0.0, 0.75, 0.166667, 0.040555, 0.0,...</td>\n",
       "      <td>GX037-87-3082362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   relevance  qid                                           features  \\\n",
       "0          0   10  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1          1   10  [0.03131, 0.666667, 0.5, 0.166667, 0.033206, 0...   \n",
       "2          1   10  [0.078682, 0.166667, 0.5, 0.333333, 0.080022, ...   \n",
       "3          1   10  [0.019058, 1.0, 1.0, 0.5, 0.022591, 0.0, 0.0, ...   \n",
       "4          0   10  [0.039477, 0.0, 0.75, 0.166667, 0.040555, 0.0,...   \n",
       "\n",
       "               docid  \n",
       "0   GX000-00-0000000  \n",
       "1  GX000-24-12369390  \n",
       "2   GX000-62-7863450  \n",
       "3   GX016-48-5543459  \n",
       "4   GX037-87-3082362  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7623b3",
   "metadata": {},
   "source": [
    "## Task 1 (20 points)\n",
    "Train **linear regression model** to predict relevance score for query-document pairs. Use scikit-learn library.  \n",
    "Using trained model, rank documents for each query according to predicted relevance score.  \n",
    "\n",
    "baseline: NDCG@10 == 0.05\n",
    "\n",
    "Answer the questions:  \n",
    "1. Which loss function did you choose and why?  \n",
    "1. Did you apply some transformations on relevance score and why?  \n",
    "    \n",
    "Use your findings in the next tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10575b76",
   "metadata": {},
   "source": [
    "## Task 2 (20 points)\n",
    "\n",
    "Implement and train **RankNet model** to rank documents in each query. Use pytorch.  \n",
    "For base model $f(x)$ you should use multilayer perceptron.  \n",
    "Note, that during training you have to consider every $(doc_i, doc_j)$ pair in the query.\n",
    "\n",
    "Answer the questions: \n",
    "1. Does the result depend on transformations on relevance score?\n",
    "\n",
    "baseline: NDCG@10 == 0.1  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6978044",
   "metadata": {},
   "source": [
    "## Task 3 (20 points)\n",
    "\n",
    "Implement and train **ListNet model** to rank documents in each query. Use pytorch.  \n",
    "For base model $\\phi(x)$ you should use multilayer perceptron.\n",
    "\n",
    "baseline: NDCG@10 == 0.15 \n",
    "\n",
    "Answer the questions:   \n",
    "1. Does the result depend on transformations on relevance score?\n",
    "1. Which model performs better: RankNet or ListNet and why?  \n",
    "1. Does your answer agree with the paper results? If they do not, what are the reasons?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba37060",
   "metadata": {},
   "source": [
    "## Task 4 (20 points)\n",
    "\n",
    "Implement and train **LambdaRank model** to rank documents in each query optimizing NDCG. Use pytorch.  \n",
    "For base model $\\phi(x)$ you should use multilayer perceptron.\n",
    "Note, that during training you have to consider every $(doc_i, doc_j)$ pair in the query.  \n",
    "\n",
    "baseline: NDCG@10 == 0.15 \n",
    "\n",
    "Answer the questions: \n",
    "1. Which model performs better: LambdaRank or ListNet and why? \n",
    "1. Does your answer agree with the paper results? If they do not, what are the reasons?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfe5f0d",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "\n",
    "Suppose we change our quality metric from NDCG to Kendal rank correlation coefficient (Kendal tau).  \n",
    "Derive and write down new $\\lambda'_{ij}$ for this metric for LambdaRank model.  \n",
    "Train LambdaRank model to rank documents in each query optimizing Kendal tau.  \n",
    "Evaluate Kendal tau for the model in task 4.  \n",
    "Compare new model performance with the model from task 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab121d37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
